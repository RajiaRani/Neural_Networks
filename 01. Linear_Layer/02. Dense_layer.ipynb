{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63296fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa5c9d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [-1.0475188e-04  1.1395361e-04 -4.7983500e-05]\n",
      " [-2.7414842e-04  3.1729150e-04 -8.6921798e-05]\n",
      " [-4.2188365e-04  5.2666257e-04 -5.5912682e-05]\n",
      " [-5.7707680e-04  7.1401405e-04 -8.9430439e-05]]\n"
     ]
    }
   ],
   "source": [
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.01* np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "dense1 = Layer_Dense(2,3)\n",
    "dense1.forward(X)\n",
    "print(dense1.output[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df175022",
   "metadata": {},
   "source": [
    "ACTIVATION FUNCTION: RELU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f4ed13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  2.  0.  3.3 0.  1.1 2.2 0. ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "inputs = [ 0, 2, -1, 3.3, -2.7, 1.1, 2.2, -100]\n",
    "outputs = np.maximum(inputs, 0)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27470d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU Activation \n",
    "class Activation_ReLU:\n",
    "    # forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Calculate output values from input\n",
    "        self.output = np.maximum(inputs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c1caf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from nnfs.datasets import spiral_data\n",
    "# create data sets \n",
    "X, y = spiral_data( samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 inputs features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "\n",
    "# Create ReLU Activation to be used with dense layer.\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Make forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "\n",
    "# Forward pass through activation function.\n",
    "# Take in output from previous layer\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "# Let's see output of the first few sample:\n",
    "print(activation1.output[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aca84d",
   "metadata": {},
   "source": [
    "ACTIVATION SOFTMAX FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3179f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "Sum along row: [15 18 21 24]\n",
      "Sum along columns: [10 26 42]\n",
      "In two dimensional along rows:  [[15 18 21 24]]\n",
      "(1, 4)\n",
      "In two dimensional along columns:  [[10]\n",
      " [26]\n",
      " [42]]\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "## Try These Excercises For Yourself\n",
    "A = [ [1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]\n",
    "print(np.sum(A))\n",
    "\n",
    "# For One Dimensional along Rows\n",
    "print('Sum along row:',np.sum(A, axis=0))\n",
    "\n",
    "# For One Dimensional along Columns\n",
    "print('Sum along columns:', np.sum(A, axis=1))\n",
    "\n",
    "#For 2 dimensional\n",
    "print('In two dimensional along rows: ', np.sum(A, axis=0, keepdims=True))\n",
    "print(np.sum(A, axis=0, keepdims=True).shape)\n",
    "#For 2 dimensional\n",
    "print('In two dimensional along columns: ', np.sum(A, axis=1, keepdims=True))\n",
    "print(np.sum(A, axis=1, keepdims=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "284677d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06414769 0.17437149 0.47399085 0.28748998]\n",
      " [0.04517666 0.90739747 0.00224921 0.04517666]\n",
      " [0.00522984 0.34875873 0.63547983 0.0105316 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [ [1, 2, 3, 2.5], \n",
    "           [2., 5., -1., 2], \n",
    "           [-1.5, 2.7, 3.3, -0.8]\n",
    "        ]\n",
    "\n",
    "#Get unnormalized probabilities\n",
    "exp_values = np.exp( inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "\n",
    "#Normalize them ton each sample\n",
    "probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "print(probabilities)\n",
    "np.sum(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5591380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOFTMAX ACTIVATION FUNCTION\n",
    "\n",
    "class Activation_Softmax:\n",
    "#Forward pss\n",
    " def forward(self, inputs):\n",
    "  #Get unnormalized probalilities\n",
    "  exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "  #Normalize them ton each sample\n",
    "  probabilities = exp_values / np.sum( exp_values, axis=1, keepdims=True)\n",
    "  self.output = probabilities\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4587becd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33333364 0.3333334  0.3333329 ]\n",
      " [0.33333385 0.3333335  0.33333266]]\n"
     ]
    }
   ],
   "source": [
    "# Create data sets \n",
    "X, y = spiral_data( samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 inputs features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "# Create ReLU Activation to be used with dense layer.\n",
    "activation1 = Activation_ReLU()\n",
    "# Second dense \n",
    "dense2 = Layer_Dense(3, 3)\n",
    "#Softmax\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "\n",
    "# Make forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "# Forward pass through activation function.\n",
    "# Take in output from previous layer\n",
    "activation1.forward(dense1.output)\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "\n",
    "# Let's see output of the first few sample:\n",
    "print(activation2.output[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1468618",
   "metadata": {},
   "source": [
    "# ADDING CATEGORICAL ENTROPY LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f3d1a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS\n",
    "class Loss:\n",
    "    # calculate the data and regularization losses\n",
    "    # given model output and ground truth values\n",
    "    def calcualtes(self, output, y):\n",
    "        #Calculate sample loss\n",
    "        sample_losses = self.forward(output, y)\n",
    "\n",
    "        # calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "\n",
    "        # return loss\n",
    "        return data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "631919be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy Loss\n",
    "class Loss_CategoricalCrossEntropy(Loss):\n",
    "    # Forward Pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Number of samples in batch\n",
    "        sample = len(y_pred)\n",
    "    # Clip data to prevent division by 0\n",
    "    # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip( y_pred, 1e-7, 1 - 1e-7)\n",
    "    # Probabilities for target values\n",
    "    # Only if categorical labels\n",
    "        if len(y_true.shape) == 1: # one dim\n",
    "            correct_confidences = y_pred_clipped[\n",
    "                range(sample),\n",
    "                y_true\n",
    "            ]\n",
    "\n",
    "        # Mask Values - only for ONE-HOT ENCODED\n",
    "        elif len(y_true.shape) == 2: # 2 dim\n",
    "            correct_confidences = np.sum(\n",
    "                y_pred_clipped*y_true,\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "        # LOSSES\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c704122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33333305 0.33333364 0.33333334]\n",
      " [0.3333327  0.333334   0.3333333 ]]\n",
      "Loss =  1.0986103\n"
     ]
    }
   ],
   "source": [
    "# Create data sets \n",
    "X, y = spiral_data( samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 inputs features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "# Create ReLU Activation to be used with dense layer.\n",
    "activation1 = Activation_ReLU()\n",
    "# Second dense \n",
    "dense2 = Layer_Dense(3, 3)\n",
    "#Softmax\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "#Create loss function\n",
    "loss_function = Loss_CategoricalCrossEntropy()\n",
    "\n",
    "\n",
    "# Make forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "# Forward pass through activation function.\n",
    "# Take in output from previous layer\n",
    "activation1.forward(dense1.output)\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "\n",
    "# Let's see output of the first few sample:\n",
    "print(activation2.output[:3])\n",
    "\n",
    "# Perform a forward pass through activation function\n",
    "# It takes the output of second dense layer here and returns loss\n",
    "loss = loss_function.calcualtes(activation2.output, y)\n",
    "\n",
    "# Print Loss function\n",
    "print(\"Loss = \" , loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fe623d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(predictions \u001b[38;5;241m==\u001b[39m y)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Print accuracy\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCURACY = \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43maccuracy\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy from output of activation2 and targets\n",
    "# Calculate values along first axis\n",
    "\n",
    "predictions = np.argmax(activation2.output, axis=1)\n",
    "if len(y.shape) == 2:\n",
    "    y = np.argmax(y , axis=1)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "\n",
    "# Print accuracy\n",
    "print(\"ACCURACY = \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
