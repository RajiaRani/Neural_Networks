{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938a666d",
   "metadata": {},
   "source": [
    "BUILDING NEURAL NETWORKS FROM SCRATCH PART 1: CODING NEURONS AND LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9e265d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d543e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [-4.3361859e-05 -8.5417814e-05 -9.9373065e-05]\n",
      " [-7.3564916e-05  1.4769069e-05 -1.5383620e-04]]\n"
     ]
    }
   ],
   "source": [
    "# Dense layer Class\n",
    "class Layer_Dense:\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "# Forward Pass\n",
    "    def forward(self, inputs):\n",
    "       # inputs (batch_size × n_inputs)\n",
    "        # weights (n_inputs × n_neurons)\n",
    "        # result → (batch_size × n_neurons)\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "\n",
    "# Create datasets \n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "# Create dense layer\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "dense1.forward(X)\n",
    "print(dense1.output[: 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a516c",
   "metadata": {},
   "source": [
    "ACTIVATION FUNCTION : RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "610c90da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  2.  0.  3.  0.  1.1 2.8 0.  1. ]\n"
     ]
    }
   ],
   "source": [
    "inputs = [0, 2, -1, 3, -2.7, 1.1, 2.8, -0.9, 1.0]\n",
    "output = np.maximum(0, inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "108a8656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELU ACTIVATION\n",
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "225c3ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "# Create Dense Layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2,3)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer)\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Make a forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "\n",
    "# Forward pass through activation function\n",
    "# Takes in output from previous layer\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "print(activation1.output[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d9dd84",
   "metadata": {},
   "source": [
    "ACTIVATION FUNCTION : SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a1aec6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06414769 0.17437149 0.47399085 0.28748998]\n",
      " [0.04517666 0.90739747 0.00224921 0.04517666]\n",
      " [0.00522984 0.34875873 0.63547983 0.0105316 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [ [1, 2, 3, 2.5], [2.0, 5.0, -1, 2], [-1.5, 2.7, 3.3, -0.8]]\n",
    "exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "print(probabilities)\n",
    "np.sum(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d800811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp( inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilities\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248e449d",
   "metadata": {},
   "source": [
    "# One Forward Pass (Without Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73b08079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33333266 0.3333335  0.33333385]\n",
      " [0.33333156 0.33333433 0.33333418]\n",
      " [0.33333084 0.3333342  0.33333492]\n",
      " [0.3333313  0.3333335  0.3333352 ]\n",
      " [0.33332995 0.33333415 0.33333594]\n",
      " [0.33332783 0.33333588 0.33333623]\n",
      " [0.33332905 0.33333412 0.33333683]\n",
      " [0.33332652 0.3333359  0.33333758]\n",
      " [0.3333312  0.33333224 0.33333656]\n",
      " [0.33332694 0.33333468 0.3333384 ]\n",
      " [0.33332413 0.33333665 0.33333918]\n",
      " [0.3333228  0.33333924 0.333338  ]\n",
      " [0.33332202 0.33333775 0.33334017]\n",
      " [0.3333213  0.33334005 0.33333862]\n",
      " [0.3333202  0.33334067 0.3333391 ]\n",
      " [0.3333211  0.33333918 0.33333975]\n",
      " [0.33331782 0.33334053 0.33334166]\n",
      " [0.3333184  0.33333862 0.3333429 ]\n",
      " [0.3333185  0.33333808 0.33334345]\n",
      " [0.3333174  0.33334225 0.33334035]\n",
      " [0.33331662 0.33334076 0.33334267]\n",
      " [0.33331826 0.33334145 0.33334032]\n",
      " [0.3333152  0.33334154 0.33334327]\n",
      " [0.3333161  0.3333422  0.33334172]\n",
      " [0.33331364 0.33334228 0.33334407]\n",
      " [0.33331195 0.3333453  0.33334273]\n",
      " [0.33330482 0.3333436  0.33335158]\n",
      " [0.3333111  0.3333414  0.33334747]\n",
      " [0.33331403 0.33334398 0.33334202]\n",
      " [0.33331066 0.333346   0.3333433 ]\n",
      " [0.33330318 0.33334416 0.33335263]\n",
      " [0.33330598 0.33334318 0.33335084]\n",
      " [0.33330482 0.33334357 0.33335155]\n",
      " [0.33329922 0.33334562 0.3333552 ]\n",
      " [0.33330187 0.33334464 0.33335346]\n",
      " [0.3333018  0.33334467 0.33335352]\n",
      " [0.33329555 0.3333469  0.33335748]\n",
      " [0.33329508 0.3333471  0.33335784]\n",
      " [0.33329737 0.33334628 0.33335638]\n",
      " [0.3332987  0.33334577 0.3333555 ]\n",
      " [0.33331764 0.33333522 0.3333471 ]\n",
      " [0.33329016 0.33334887 0.33336097]\n",
      " [0.33328876 0.33334938 0.33336186]\n",
      " [0.3332882  0.3333496  0.33336225]\n",
      " [0.33331084 0.33333862 0.33335054]\n",
      " [0.3333146  0.33333614 0.3333493 ]\n",
      " [0.33328685 0.33335006 0.3333631 ]\n",
      " [0.3333255  0.33332935 0.33334517]\n",
      " [0.333324   0.33332857 0.33334744]\n",
      " [0.33331734 0.33333382 0.33334884]\n",
      " [0.3332807  0.33335227 0.33336702]\n",
      " [0.33332294 0.33332804 0.33334896]\n",
      " [0.3332912  0.33334848 0.3333603 ]\n",
      " [0.33332148 0.3333273  0.33335122]\n",
      " [0.33332035 0.33332673 0.33335292]\n",
      " [0.33331996 0.33332652 0.3333535 ]\n",
      " [0.33328456 0.33335087 0.33336458]\n",
      " [0.33332312 0.33332813 0.33334878]\n",
      " [0.33331373 0.33332923 0.333357  ]\n",
      " [0.3333193  0.33332616 0.33335453]\n",
      " [0.33332357 0.33332837 0.3333481 ]\n",
      " [0.33331874 0.3333259  0.33335534]\n",
      " [0.33331078 0.33332992 0.3333593 ]\n",
      " [0.33332092 0.333327   0.33335203]\n",
      " [0.33327428 0.33336005 0.33336568]\n",
      " [0.3332792  0.33335227 0.33336854]\n",
      " [0.333286   0.33334568 0.3333683 ]\n",
      " [0.33330125 0.33333445 0.33336428]\n",
      " [0.33328578 0.33334512 0.33336914]\n",
      " [0.3332881  0.33334294 0.33336893]\n",
      " [0.33329067 0.3333407  0.3333686 ]\n",
      " [0.33326858 0.33336133 0.33337006]\n",
      " [0.33326975 0.33336893 0.33336136]\n",
      " [0.33326644 0.33336288 0.3333707 ]\n",
      " [0.33326566 0.33336303 0.3333713 ]\n",
      " [0.33326578 0.3333703  0.33336392]\n",
      " [0.3332703  0.33336857 0.33336106]\n",
      " [0.3332623  0.33336926 0.33336845]\n",
      " [0.3332632  0.33336252 0.3333743 ]\n",
      " [0.3332801  0.33336273 0.33335724]\n",
      " [0.3332593  0.33336845 0.33337224]\n",
      " [0.33327886 0.33336344 0.33335772]\n",
      " [0.33327082 0.33336833 0.33336085]\n",
      " [0.33326167 0.33337346 0.33336487]\n",
      " [0.33326513 0.33335915 0.3333757 ]\n",
      " [0.33326384 0.33336103 0.33337513]\n",
      " [0.33326322 0.3333629  0.33337384]\n",
      " [0.33326226 0.33336282 0.33337492]\n",
      " [0.33326155 0.3333613  0.33337712]\n",
      " [0.3332716  0.3333665  0.3333619 ]\n",
      " [0.333262   0.33336604 0.33337203]\n",
      " [0.33327034 0.33336857 0.33336106]\n",
      " [0.33324945 0.3333635  0.33338708]\n",
      " [0.33323404 0.33336908 0.3333969 ]\n",
      " [0.33325568 0.33336127 0.33338305]\n",
      " [0.3332353  0.3333686  0.3333961 ]\n",
      " [0.3332463  0.33336464 0.33338904]\n",
      " [0.33323884 0.33336732 0.33339384]\n",
      " [0.33323184 0.33336985 0.33339834]\n",
      " [0.33333334 0.33333334 0.33333334]\n",
      " [0.33333245 0.33333367 0.3333339 ]\n",
      " [0.3333312  0.3333341  0.33333468]\n",
      " [0.3333309  0.33333424 0.33333492]\n",
      " [0.3333295  0.33333468 0.33333576]\n",
      " [0.333328   0.33333522 0.3333367 ]\n",
      " [0.33332735 0.3333355  0.3333372 ]\n",
      " [0.333326   0.33333597 0.33333802]\n",
      " [0.33332905 0.33333448 0.3333365 ]\n",
      " [0.33332717 0.33333552 0.33333734]\n",
      " [0.3333241  0.33333665 0.33333924]\n",
      " [0.33332202 0.3333374  0.33334056]\n",
      " [0.33332467 0.33333644 0.33333886]\n",
      " [0.33332244 0.33333728 0.33334032]\n",
      " [0.33332887 0.33333346 0.33333766]\n",
      " [0.33332318 0.3333369  0.33333996]\n",
      " [0.33332762 0.33333242 0.3333399 ]\n",
      " [0.33332944 0.33333135 0.33333918]\n",
      " [0.33332992 0.3333322  0.3333379 ]\n",
      " [0.33332276 0.33333626 0.333341  ]\n",
      " [0.33332926 0.33333126 0.33333948]\n",
      " [0.33332115 0.3333369  0.33334196]\n",
      " [0.3333235  0.33333334 0.33334315]\n",
      " [0.3333237  0.33333296 0.3333434 ]\n",
      " [0.33331606 0.33333802 0.33334592]\n",
      " [0.33332756 0.3333304  0.33334205]\n",
      " [0.3333165  0.33333695 0.33334658]\n",
      " [0.33331054 0.33334178 0.33334768]\n",
      " [0.3333241  0.33333135 0.33334455]\n",
      " [0.33332497 0.33333057 0.33334443]\n",
      " [0.33330607 0.33334568 0.33334824]\n",
      " [0.33331007 0.33334017 0.33334973]\n",
      " [0.333306   0.33334365 0.3333503 ]\n",
      " [0.3333072  0.33334187 0.33335093]\n",
      " [0.33331662 0.33333436 0.33334908]\n",
      " [0.33330256 0.33335054 0.33334693]\n",
      " [0.33332112 0.33333096 0.3333479 ]\n",
      " [0.33330122 0.33335128 0.33334747]\n",
      " [0.33329883 0.33334893 0.33335227]\n",
      " [0.3332977  0.3333508  0.33335146]\n",
      " [0.33329678 0.33335054 0.33335263]\n",
      " [0.3332992  0.33335245 0.33334836]\n",
      " [0.3332989  0.3333526  0.33334848]\n",
      " [0.33330002 0.33334893 0.33335102]\n",
      " [0.3332961  0.33335415 0.3333497 ]\n",
      " [0.33329657 0.3333539  0.33334953]\n",
      " [0.33329597 0.33335423 0.3333498 ]\n",
      " [0.33330232 0.33335072 0.33334702]\n",
      " [0.33329728 0.33335352 0.3333492 ]\n",
      " [0.33329386 0.33334857 0.33335754]\n",
      " [0.33329085 0.3333486  0.33336052]\n",
      " [0.3332888  0.33335826 0.33335292]\n",
      " [0.3332939  0.3333554  0.3333507 ]\n",
      " [0.33329788 0.3333528  0.33334932]\n",
      " [0.3332858  0.33335042 0.33336374]\n",
      " [0.33329126 0.33335343 0.3333553 ]\n",
      " [0.3332797  0.33335263 0.3333677 ]\n",
      " [0.33327284 0.3333551  0.33337206]\n",
      " [0.33327222 0.33335528 0.33337244]\n",
      " [0.33328563 0.33335266 0.3333617 ]\n",
      " [0.33328485 0.33335277 0.33336243]\n",
      " [0.33329296 0.3333557  0.3333513 ]\n",
      " [0.33326793 0.33335686 0.3333752 ]\n",
      " [0.33327982 0.3333526  0.33336762]\n",
      " [0.3332657  0.3333577  0.33337668]\n",
      " [0.33326733 0.3333571  0.33337563]\n",
      " [0.3332679  0.3333569  0.33337525]\n",
      " [0.33328667 0.33335003 0.33336326]\n",
      " [0.33326107 0.3333593  0.3333796 ]\n",
      " [0.33326304 0.33335862 0.33337831]\n",
      " [0.33325925 0.33336    0.33338076]\n",
      " [0.33328155 0.33335194 0.33336648]\n",
      " [0.33326843 0.33335668 0.3333749 ]\n",
      " [0.3333166  0.33332482 0.33335862]\n",
      " [0.33327696 0.33335364 0.33336943]\n",
      " [0.33330348 0.3333375  0.33335903]\n",
      " [0.3332953  0.33334228 0.3333624 ]\n",
      " [0.33331794 0.3333255  0.3333566 ]\n",
      " [0.33331615 0.3333297  0.33335412]\n",
      " [0.33327875 0.3333527  0.3333685 ]\n",
      " [0.33331776 0.3333254  0.3333568 ]\n",
      " [0.3333155  0.33332425 0.3333603 ]\n",
      " [0.33329904 0.3333389  0.3333621 ]\n",
      " [0.33331373 0.3333302  0.33335602]\n",
      " [0.33331728 0.33332515 0.33335757]\n",
      " [0.33331302 0.333323   0.33336395]\n",
      " [0.3333136  0.3333233  0.33336312]\n",
      " [0.3332982  0.33333844 0.33336335]\n",
      " [0.33331314 0.33332306 0.3333638 ]\n",
      " [0.3332635  0.33335578 0.33338076]\n",
      " [0.3332698  0.33334985 0.3333803 ]\n",
      " [0.33326364 0.3333547  0.33338165]\n",
      " [0.33327663 0.33334395 0.33337945]\n",
      " [0.3332522  0.33337873 0.33336908]\n",
      " [0.33326417 0.33335292 0.33338287]\n",
      " [0.33326244 0.33335403 0.33338356]\n",
      " [0.33326268 0.33335337 0.33338395]\n",
      " [0.3332554  0.3333595  0.33338508]\n",
      " [0.33324546 0.3333804  0.3333742 ]\n",
      " [0.33329538 0.33332953 0.33337516]\n",
      " [0.33333334 0.33333334 0.33333334]\n",
      " [0.33333254 0.3333338  0.33333367]\n",
      " [0.33333158 0.33333406 0.3333344 ]\n",
      " [0.33333078 0.3333343  0.33333492]\n",
      " [0.33332977 0.33333528 0.33333495]\n",
      " [0.33332878 0.33333558 0.33333567]\n",
      " [0.33332846 0.33333606 0.3333355 ]\n",
      " [0.33332694 0.33333644 0.33333662]\n",
      " [0.33332697 0.33333614 0.33333692]\n",
      " [0.3333252  0.3333376  0.3333372 ]\n",
      " [0.33332613 0.3333374  0.33333653]\n",
      " [0.3333259  0.33333737 0.33333668]\n",
      " [0.33332434 0.33333772 0.3333379 ]\n",
      " [0.33332384 0.33333814 0.33333802]\n",
      " [0.33332255 0.33333844 0.333339  ]\n",
      " [0.33332157 0.33333874 0.33333972]\n",
      " [0.33331764 0.33333898 0.3333434 ]\n",
      " [0.3333196  0.33333907 0.33334127]\n",
      " [0.33331546 0.33333975 0.3333448 ]\n",
      " [0.33331817 0.33334002 0.33334178]\n",
      " [0.33331636 0.33333945 0.33334422]\n",
      " [0.333315   0.33333993 0.33334506]\n",
      " [0.33330998 0.33334172 0.33334827]\n",
      " [0.33331364 0.3333404  0.33334595]\n",
      " [0.3333121  0.333341   0.33334696]\n",
      " [0.3333074  0.33334267 0.33334997]\n",
      " [0.33330572 0.33334327 0.33335102]\n",
      " [0.33331156 0.33334237 0.3333461 ]\n",
      " [0.33330458 0.33334365 0.33335173]\n",
      " [0.33331227 0.33334088 0.33334678]\n",
      " [0.33330232 0.33334446 0.33335316]\n",
      " [0.33330235 0.3333445  0.3333532 ]\n",
      " [0.33331096 0.3333414  0.33334768]\n",
      " [0.33331195 0.33334044 0.33334765]\n",
      " [0.33332756 0.3333304  0.33334205]\n",
      " [0.33331662 0.33333695 0.33334643]\n",
      " [0.3333054  0.3333434  0.33335125]\n",
      " [0.33331335 0.33333865 0.33334804]\n",
      " [0.333327   0.33333045 0.33334252]\n",
      " [0.33332598 0.3333296  0.3333444 ]\n",
      " [0.33330703 0.3333422  0.33335078]\n",
      " [0.33332527 0.3333292  0.33334547]\n",
      " [0.33332136 0.3333293  0.33334938]\n",
      " [0.3333264  0.3333298  0.33334383]\n",
      " [0.33332488 0.33332902 0.33334613]\n",
      " [0.3333203  0.33333302 0.33334672]\n",
      " [0.3333213  0.33333227 0.33334646]\n",
      " [0.33332267 0.33332792 0.33334938]\n",
      " [0.3333149  0.33333153 0.33335364]\n",
      " [0.33332208 0.3333276  0.33335033]\n",
      " [0.3333007  0.33334044 0.33335885]\n",
      " [0.3333     0.33334064 0.3333594 ]\n",
      " [0.33332086 0.33332697 0.33335215]\n",
      " [0.33329508 0.33334377 0.33336115]\n",
      " [0.33330622 0.3333353  0.3333585 ]\n",
      " [0.3332975  0.33334112 0.3333614 ]\n",
      " [0.333283   0.33335504 0.33336192]\n",
      " [0.333286   0.33335984 0.33335418]\n",
      " [0.33331504 0.33332875 0.33335623]\n",
      " [0.33328837 0.333347   0.33336464]\n",
      " [0.33328032 0.3333627  0.33335692]\n",
      " [0.33328074 0.33335367 0.33336556]\n",
      " [0.33327973 0.3333542  0.33336607]\n",
      " [0.33328623 0.3333597  0.33335406]\n",
      " [0.33327493 0.33336237 0.33336273]\n",
      " [0.33327904 0.33336374 0.33335727]\n",
      " [0.33327353 0.33336434 0.33336213]\n",
      " [0.3332767  0.33335435 0.33336893]\n",
      " [0.33327287 0.33336636 0.33336076]\n",
      " [0.3332857  0.33336    0.3333543 ]\n",
      " [0.33328003 0.33336318 0.3333568 ]\n",
      " [0.33327144 0.33336797 0.33336058]\n",
      " [0.33327207 0.3333554  0.33337256]\n",
      " [0.33328375 0.3333602  0.33335602]\n",
      " [0.33327186 0.33336774 0.3333604 ]\n",
      " [0.33327347 0.33335486 0.33337164]\n",
      " [0.3332724  0.33335632 0.33337128]\n",
      " [0.33327895 0.33336177 0.33335924]\n",
      " [0.33327153 0.3333557  0.33337277]\n",
      " [0.3332627  0.33335873 0.33337852]\n",
      " [0.3332649  0.33335793 0.33337715]\n",
      " [0.3332675  0.333357   0.33337548]\n",
      " [0.3332789  0.33336344 0.33335772]\n",
      " [0.3332673  0.3333571  0.33337563]\n",
      " [0.3332545  0.3333617  0.3333838 ]\n",
      " [0.33326155 0.33335915 0.33337927]\n",
      " [0.33325055 0.3333631  0.33338633]\n",
      " [0.3332425  0.33336598 0.33339146]\n",
      " [0.33324417 0.3333654  0.33339044]\n",
      " [0.33326206 0.3333601  0.3333778 ]\n",
      " [0.33323902 0.33336726 0.33339372]\n",
      " [0.33323663 0.33336812 0.33339527]\n",
      " [0.33323893 0.33336732 0.33339378]\n",
      " [0.33323583 0.3333684  0.33339575]\n",
      " [0.33324096 0.33336657 0.33339247]\n",
      " [0.33323455 0.33336887 0.33339658]\n",
      " [0.33328414 0.33334538 0.33337048]\n",
      " [0.33325815 0.3333604  0.3333815 ]\n",
      " [0.3332895  0.33334166 0.33336884]\n",
      " [0.33328643 0.33334336 0.3333702 ]]\n",
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33333266 0.3333335  0.33333385]\n",
      " [0.33333156 0.33333433 0.33333418]\n",
      " [0.33333084 0.3333342  0.33333492]\n",
      " [0.3333313  0.3333335  0.3333352 ]]\n"
     ]
    }
   ],
   "source": [
    "X, y = spiral_data(samples=100, classes=3)\n",
    "dense1 = Layer_Dense(2,3)\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "dense2 = Layer_Dense(3,3)\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "dense1.forward(X)\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "print(activation2.output[:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
